# -*- coding: utf-8 -*-
"""Copy of Submission-1-NLP-BPML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cDRIIBtsE1jVF-VibukR8bqlnno-JRvS

Nama : Iklima Mardiana

Dataset : https://www.kaggle.com/datasets/joebeachcapital/restaurant-reviews
"""

# dataframe
import pandas as pd
import re

# split data
from sklearn.model_selection import train_test_split

# preprocessing dan layer
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,Bidirectional
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

# visualisasi plot
import matplotlib.pyplot as plt

df = pd.read_csv('twitter_sentiment.csv')
df = df.drop(columns=['Borderlands', '2401'])
df = df.rename(columns={'Positive': 'category', 'im getting on borderlands and i will murder you all ,': 'text'})
df

# Menghapus nilai NaN
df.isnull().values.any()
df = df.dropna(subset=['category', 'text'], how='any')

# # Menghapus special character di kolom text
df['text'] = df['text'].map(lambda x: re.sub(r'\W+', ' ', x))
df

# melakukan one-hot-encoding

category = pd.get_dummies(df.category)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='category')
df_baru

# mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values

text = df_baru['text'].values
label = df_baru[['Irrelevant',	'Negative',	'Neutral',	'Positive']].values

# membagi data untuk training dan data testing

text_train, text_test, label_train, label_test = train_test_split(text, label, test_size=0.2)

# mengubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)

sekuens_train = tokenizer.texts_to_sequences(text_train)
sekuens_test = tokenizer.texts_to_sequences(text_test)

max_sequence_length = 66
padded_train = pad_sequences(sekuens_train, maxlen=max_sequence_length)
padded_test = pad_sequences(sekuens_test, maxlen=max_sequence_length)

# arsitektur model dengan menggunakan layer Embedding

model = Sequential([
    Embedding(input_dim=5000, output_dim=16, input_length=max_sequence_length),
    Bidirectional(LSTM(64)),
    Dense(126, activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(4, activation='softmax')
])

# Model compiile dengan optimizer Adam

model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=0.0001),metrics=['accuracy'])

# Penggunaan callback untuk accuracy dan val diatas 90%

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.86 and logs.get('val_accuracy')>0.86):
      print("\nAkurasi train dan validasi didapat telah mencapai nilai > 86%!")
      self.model.stop_training = True
callbacks = myCallback()

# melatih model

history = model.fit(
    padded_train,
    label_train,
    epochs=50,
    validation_data=(padded_test, label_test),
    batch_size=128,
    verbose=2,
    callbacks=[callbacks])

# Plot Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()